# ğŸš— **RL Car Simulation**

### *A Reinforcement Learning-based Autonomous Driving Simulation using Deep Q-Networks (DQN) and PyGame*

---

## ğŸ§  **Overview**

This project demonstrates an **autonomous driving simulation** powered by **Deep Q-Learning (DQN)**, where a virtual car learns to navigate complex tracks, avoid collisions, and optimize driving efficiency â€” **all through experience**.

The agent perceives its surroundings using simulated **distance sensors**, processes observations through a **neural network**, and takes optimal driving actions based on learned Q-values.
Built with **PyGame** for visualization ğŸ® and **PyTorch** for the deep learning backend ğŸ”¥, the project provides a seamless integration of AI learning and interactive simulation.

![Simulation Output](assets/output_screenshot.png)

---

## âš™ï¸ **Key Features**

âœ… **Deep Q-Learning Agent:**
Trains a neural network to approximate the Q-value function for intelligent driving decisions.

ğŸ—ºï¸ **Custom Map Builder:**
Design and save your own driving tracks.

ğŸ¥ **Real-time Visualization:**
Observe the car as it learns to drive smarter over time.

ğŸ“Š **Performance Tracking:**
Monitor **reward curves**, **loss curves**, and training progress with detailed logs.

ğŸ’¾ **Save & Load Models:**
Easily persist and reload trained models for evaluation or further training.

---

## ğŸ§© **Project Structure**

```bash
.
â”œâ”€â”€ assets/             # Images, visualizations, and training graphs
â”œâ”€â”€ saved_maps/         # User-created maps and tracks
â”œâ”€â”€ saved_models/       # Trained models, checkpoints, and logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App/            # Core simulation and control logic
â”‚   â”œâ”€â”€ MachineLearning/# DQN architecture and agent logic
â”‚   â””â”€â”€ Utils/          # Helper functions, constants, and global settings
â”œâ”€â”€ main.py             # Entry point for simulation and training
â””â”€â”€ requirements.txt    # Python dependencies
```

---

## ğŸš€ **Installation**

### ğŸ§¾ Clone the Repository

```bash
git clone https://github.com/sam12fak/Autonomous-Driving-Using-Reinforcement-Learning-.git
cd Autonomous-Driving-Using-Reinforcement-Learning-
```

### ğŸ§± Create a Virtual Environment (Recommended)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ **Usage**

### â–¶ï¸ Run the Simulation (GUI Mode)

```bash
python main.py
```

### âš¡ Train in Background (Headless Mode)

```bash
python main.py --background --map "SanFrancisco" --min-epsilon
```

### ğŸ§  Arguments

| Argument           | Description                                          |
| ------------------ | ---------------------------------------------------- |
| `--background`     | Runs without rendering for faster training           |
| `--map [MAP_NAME]` | Loads a specific track                               |
| `--min-epsilon`    | Stops training when exploration rate reaches minimum |
| `--verbose [0-3]`  | Sets verbosity level for logging                     |

---

## ğŸ“ˆ **Examples & Results**

### ğŸï¸ Training Progress

The car starts with random movements and gradually learns to stay on the road, avoid obstacles, and maximize cumulative rewards.

**Loss Curve:**
Shows the reduction in Q-value prediction error over time.

![Loss Curve](assets/loss_curve.png)

**Reward Curve:**
Displays increasing stability and reward gains as the agent converges.

![Reward Curve](assets/rewards_curve.png)

ğŸ–¼ï¸ *Visual outputs and graphs can be found in the `assets/` directory.*

---

## âš™ï¸ **Configuration**

Adjust core simulation and learning parameters in:
ğŸ“‚ `src/Utils/global_settings.py`

**Key Parameters:**

* `WIDTH`, `HEIGHT`: Simulation window dimensions
* `Q_LEARNING_SETTINGS`: Contains hyperparameters such as:

  * Learning rate (Î±)
  * Discount factor (Î³)
  * Epsilon decay schedule
  * Replay buffer size
  * Target update frequency

---

## ğŸ§ª **Technical Highlights**

* Implementation of **Deep Q-Network (DQN)** using PyTorch
* Experience replay and target network stabilization
* Custom reward functions for lane-following and collision avoidance
* Modular and scalable simulation design
* Compatible with any custom map generated in PyGame

---

## ğŸ¤ **Contributing**

Contributions are highly encouraged!

* Fork the repo
* Create a feature branch
* Commit your changes
* Open a pull request

Issues, feature requests, or performance improvements are welcome!

---

## ğŸ“œ **License**

This project is licensed under the **MIT License** â€” see the [LICENSE](./LICENSE) file for details.

---

## ğŸ§­ **Future Enhancements**

ğŸ”¹ Integration with **Double DQN / Dueling DQN** for improved stability
ğŸ”¹ Addition of **continuous control (DDPG / PPO)**
ğŸ”¹ Implementation of **traffic and pedestrian agents**
ğŸ”¹ Visualization dashboard for training analytics

---

### ğŸŒŸ *â€œTeaching cars to drive â€” one reward at a time.â€*
